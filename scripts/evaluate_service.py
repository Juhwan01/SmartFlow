"""
ì„œë¹„ìŠ¤ ì „ì²´ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)

âš ï¸ ì¤‘ìš”: Test ë°ì´í„°ë¡œ Multi-Agent ì‹œìŠ¤í…œì˜ ì‹¤ì œ ì„±ëŠ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤.
ML ëª¨ë¸ í‰ê°€ê°€ ì•„ë‹Œ, íŒŒë¼ë¯¸í„° ì¡°ì • ì‹œìŠ¤í…œì˜ ì‹¤ì œ íš¨ê³¼ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.

ëª©ì :
- Test ë°ì´í„°ë¡œ ì„œë¹„ìŠ¤ ì „ì²´ ì‹œë®¬ë ˆì´ì…˜
- íŒŒë¼ë¯¸í„° ì¡°ì • ì „í›„ í’ˆì§ˆ ë¹„êµ
- Ground Truth ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ ì‚°ì¶œ
- ë¶ˆëŸ‰ ê°ì†Œìœ¨, í’ˆì§ˆ íšŒë³µìœ¨ ë“± ì‹¤ì œ ì„±ëŠ¥ ê²€ì¦
"""
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import numpy as np
import pandas as pd
import pickle
import json
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from loguru import logger
from datetime import datetime
from typing import Dict, List
from dataclasses import dataclass, asdict


@dataclass
class SampleResult:
    """ê°œë³„ ìƒ˜í”Œ í‰ê°€ ê²°ê³¼"""
    sample_id: int
    ground_truth: float  # ì‹¤ì œ ìš©ì ‘ ê°•ë„
    baseline_prediction: float  # ì¡°ì • ì—†ì´ ì˜ˆì¸¡
    adjusted_prediction: float  # ì¡°ì • í›„ ì˜ˆì¸¡
    is_anomaly: bool  # ì´ìƒ ê°ì§€ ì—¬ë¶€
    adjustment_applied: bool  # ì¡°ì • ì ìš© ì—¬ë¶€
    improvement: float  # ê°œì„ ëŸ‰ (ì¡°ì • í›„ - ì¡°ì • ì „)
    meets_threshold_baseline: bool  # ì¡°ì • ì „ í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡±
    meets_threshold_adjusted: bool  # ì¡°ì • í›„ í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡±
    defect_prevented: bool  # ë¶ˆëŸ‰ ë°©ì§€ ì—¬ë¶€


@dataclass
class ServiceMetrics:
    """ì„œë¹„ìŠ¤ ì „ì²´ í‰ê°€ ì§€í‘œ"""
    # ê¸°ë³¸ í†µê³„
    total_samples: int
    anomalies_detected: int
    adjustments_made: int

    # ì˜ˆì¸¡ ì •í™•ë„ (Ground Truth ê¸°ë°˜)
    baseline_mae: float  # ì¡°ì • ì „ MAE
    adjusted_mae: float  # ì¡°ì • í›„ MAE
    mae_improvement_pct: float  # MAE ê°œì„ ìœ¨

    # ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ
    defects_before_adjustment: int  # ì¡°ì • ì „ ë¶ˆëŸ‰ ìˆ˜
    defects_after_adjustment: int  # ì¡°ì • í›„ ë¶ˆëŸ‰ ìˆ˜
    defects_prevented: int  # ë°©ì§€ëœ ë¶ˆëŸ‰ ìˆ˜
    defect_reduction_rate: float  # ë¶ˆëŸ‰ ê°ì†Œìœ¨
    quality_recovery_rate: float  # í’ˆì§ˆ íšŒë³µìœ¨

    # ë¹„ìš© íš¨ê³¼
    cost_per_defect: float
    estimated_cost_saving: float

    # ì¡°ì • íš¨ê³¼ì„±
    avg_improvement_per_adjustment: float  # ì¡°ì •ë‹¹ í‰ê·  ê°œì„ ëŸ‰
    successful_adjustments: int  # ì„±ê³µí•œ ì¡°ì • ìˆ˜
    adjustment_success_rate: float  # ì¡°ì • ì„±ê³µë¥ 


class ServiceEvaluator:
    """ì„œë¹„ìŠ¤ ì „ì²´ í‰ê°€ê¸°"""

    def __init__(
        self,
        quality_threshold: float = 0.90,
        cost_per_defect: float = 100.0
    ):
        self.quality_threshold = quality_threshold
        self.cost_per_defect = cost_per_defect

        self.model = None
        self.scaler = None
        self.test_data = None

        self.sample_results: List[SampleResult] = []
        self.service_metrics: ServiceMetrics = None

    def load_artifacts(self):
        """ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, Test ë°ì´í„° ë¡œë“œ"""
        logger.info("=" * 70)
        logger.info("ì„œë¹„ìŠ¤ í‰ê°€ ì¤€ë¹„ ì¤‘...")
        logger.info("=" * 70)

        # 1. ëª¨ë¸ ë¡œë“œ
        model_path = Path("models/quality_predictor.pkl")
        if not model_path.exists():
            raise FileNotFoundError(
                f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}\n"
                "ë¨¼ì € 'python scripts/train_model.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
            )

        with open(model_path, 'rb') as f:
            self.model = pickle.load(f)
        logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ: {model_path}")

        # 2. ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        scaler_path = Path("models/scaler.pkl")
        with open(scaler_path, 'rb') as f:
            self.scaler = pickle.load(f)
        logger.info(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ: {scaler_path}")

        # 3. Test ë°ì´í„° ë¡œë“œ
        test_path = Path("data/test_set.csv")
        if not test_path.exists():
            raise FileNotFoundError(
                f"Test ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {test_path}\n"
                "ë¨¼ì € 'python scripts/train_model.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
            )

        self.test_data = pd.read_csv(test_path)
        logger.info(f"âœ… Test ë°ì´í„° ë¡œë“œ: {test_path} ({len(self.test_data)} samples)")

        logger.info("=" * 70)

    def _detect_anomaly(self, features: np.ndarray, sample_id: int) -> bool:
        """
        ì´ìƒ ê°ì§€ (ë‘ê»˜ í¸ì°¨ ê¸°ì¤€)

        Note: Test ë°ì´í„°ëŠ” ì´ë¯¸ ìŠ¤ì¼€ì¼ë§ëœ ìƒíƒœì´ë¯€ë¡œ,
        ì •ê·œí™”ëœ ê°’ì—ì„œ ì´ìƒì„ ê°ì§€í•©ë‹ˆë‹¤.
        """
        # Feature 0ë²ˆì´ press_thickness (ìŠ¤ì¼€ì¼ë§ëœ ê°’)
        # ì„ê³„ê°’ ê¸°ë°˜ ì´ìƒ ê°ì§€ (ê°„ë‹¨í•œ ê·œì¹™)
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ anomaly detection í•„ìš”

        # ì—¬ê¸°ì„œëŠ” ì¼ë¶€ ìƒ˜í”Œì„ ë¬´ì‘ìœ„ë¡œ "ì´ìƒ"ìœ¼ë¡œ í‘œì‹œ (ì‹œë®¬ë ˆì´ì…˜)
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë‘ê»˜ í¸ì°¨, ì„¼ì„œ ê°’ ë“±ì„ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨

        # ê°„ë‹¨íˆ: 10ê°œë‹¹ 1ê°œëŠ” ì´ìƒìœ¼ë¡œ ê°„ì£¼ (ì‹¤ì œë¡œëŠ” ë°ì´í„° ê¸°ë°˜ íŒë‹¨)
        return sample_id % 10 == 0

    def _simulate_adjustment(
        self,
        features: np.ndarray,
        is_anomaly: bool
    ) -> tuple[np.ndarray, bool]:
        """
        íŒŒë¼ë¯¸í„° ì¡°ì • ì‹œë®¬ë ˆì´ì…˜

        ì´ìƒì´ ê°ì§€ë˜ë©´ Multi-Agentê°€ ì œì•ˆí•œ ì¡°ì •ê°’ì„ ì ìš©í•œë‹¤ê³  ê°€ì •
        ì‹¤ì œë¡œëŠ” NegotiationAgent + CoordinatorAgent í˜¸ì¶œ í•„ìš”

        Returns:
            (ì¡°ì •ëœ features, ì¡°ì • ì ìš© ì—¬ë¶€)
        """
        if not is_anomaly:
            return features, False

        # ì¡°ì •ê°’ ì ìš© (ì‹œë®¬ë ˆì´ì…˜)
        # ì‹¤ì œë¡œëŠ” Multi-Agentì˜ í˜‘ìƒ ê²°ê³¼ë¥¼ ì‚¬ìš©
        adjusted_features = features.copy()

        # ì˜ˆ: ìš©ì ‘ íŒŒë¼ë¯¸í„° ì¡°ì • (feature 3-8ë²ˆ)
        # - ì „ë¥˜(temp1) +3% ì¦ê°€
        # - ì†ë„(temp3) -5% ê°ì†Œ
        # - ì••ë ¥ +2% ì¦ê°€
        if len(adjusted_features[0]) > 3:
            adjusted_features[0, 3] *= 1.03  # welding_temp1 (ì „ë¥˜ ê´€ë ¨)
        if len(adjusted_features[0]) > 6:
            adjusted_features[0, 6] *= 0.95  # welding_temp3 (ì†ë„ ê´€ë ¨)
        if len(adjusted_features[0]) > 5:
            adjusted_features[0, 5] *= 1.02  # welding_pressure

        return adjusted_features, True

    def evaluate_samples(self):
        """ëª¨ë“  Test ìƒ˜í”Œì— ëŒ€í•´ í‰ê°€"""
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ” Test ìƒ˜í”Œ í‰ê°€ ì‹œì‘")
        logger.info("=" * 70)

        target_col = "welding_strength"
        X_test = self.test_data.drop(columns=[target_col]).values
        y_test = self.test_data[target_col].values

        # ===================================================================
        # ë„ë©”ì¸ ê¸°ë°˜ í’ˆì§ˆ ê¸°ì¤€ ì„¤ì • (ì œì¡° í‘œì¤€ Â±10% í¸ì°¨)
        # ===================================================================
        # Setpoint (ëª©í‘œê°’): 12.0500 (ë°ì´í„°ì…‹ ë¬¸ì„œ ê¸°ì¤€)
        # í’ˆì§ˆ í—ˆìš© ë²”ìœ„: Â±10% deviation from setpoint
        # LSL (Lower Spec Limit): 10.8450 (90% of setpoint)
        # USL (Upper Spec Limit): 13.2550 (110% of setpoint)
        #
        # ì°¸ê³ : data_explain.txt - "Each measurement has a target or Setpoint"
        #       ì œì¡°ì—… í‘œì¤€ìœ¼ë¡œ Â±10% í¸ì°¨ëŠ” ì¼ë°˜ì ì¸ í’ˆì§ˆ í—ˆìš© ë²”ìœ„
        # ===================================================================
        SETPOINT = 12.0500  # Stage2.Output.Measurement0.U.Setpoint (ìƒìˆ˜ê°’)
        TOLERANCE_PCT = 0.10  # Â±10% í—ˆìš© í¸ì°¨
        LSL = SETPOINT * (1 - TOLERANCE_PCT)  # 10.8450
        USL = SETPOINT * (1 + TOLERANCE_PCT)  # 13.2550

        logger.info(f"ì´ {len(X_test)}ê°œ ìƒ˜í”Œ í‰ê°€ ì¤‘...")
        logger.info(f"í’ˆì§ˆ ê¸°ì¤€ (ì œì¡° í‘œì¤€):")
        logger.info(f"  - Setpoint (ëª©í‘œê°’): {SETPOINT:.4f}")
        logger.info(f"  - LSL (í•˜í•œ): {LSL:.4f} ({SETPOINT} - {TOLERANCE_PCT*100:.0f}%)")
        logger.info(f"  - USL (ìƒí•œ): {USL:.4f} ({SETPOINT} + {TOLERANCE_PCT*100:.0f}%)")
        logger.info(f"  - í—ˆìš© ë²”ìœ„: [{LSL:.4f}, {USL:.4f}]")

        for i in range(len(X_test)):
            features = X_test[i:i+1]  # (1, n_features)
            ground_truth = y_test[i]

            # 1. ì´ìƒ ê°ì§€
            is_anomaly = self._detect_anomaly(features, i)

            # 2. ì¡°ì • ì—†ì´ ì˜ˆì¸¡ (Baseline)
            baseline_pred = self.model.predict(features)[0]

            # 3. ì¡°ì •ê°’ ì ìš© ì‹œë®¬ë ˆì´ì…˜
            adjusted_features, adjustment_applied = self._simulate_adjustment(
                features, is_anomaly
            )

            # 4. ì¡°ì • í›„ ì˜ˆì¸¡
            if adjustment_applied:
                adjusted_pred = self.model.predict(adjusted_features)[0]
            else:
                adjusted_pred = baseline_pred

            # 5. í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€ (ì œì¡° í‘œì¤€: Â±10% ë²”ìœ„ ë‚´)
            meets_baseline = (LSL <= baseline_pred <= USL)
            meets_adjusted = (LSL <= adjusted_pred <= USL)

            # 6. ë¶ˆëŸ‰ ë°©ì§€ ì—¬ë¶€
            # ì¡°ì • ì „ì—ëŠ” ë¶ˆëŸ‰ì´ì—ˆì§€ë§Œ, ì¡°ì • í›„ í•©ê²©
            defect_prevented = (not meets_baseline) and meets_adjusted

            # 7. ê°œì„ ëŸ‰
            improvement = adjusted_pred - baseline_pred

            # ê²°ê³¼ ì €ì¥
            sample_result = SampleResult(
                sample_id=i,
                ground_truth=ground_truth,
                baseline_prediction=baseline_pred,
                adjusted_prediction=adjusted_pred,
                is_anomaly=is_anomaly,
                adjustment_applied=adjustment_applied,
                improvement=improvement,
                meets_threshold_baseline=meets_baseline,
                meets_threshold_adjusted=meets_adjusted,
                defect_prevented=defect_prevented
            )
            self.sample_results.append(sample_result)

            # ì§„í–‰ ìƒí™© ì¶œë ¥
            if (i + 1) % 500 == 0:
                logger.info(f"  ì§„í–‰: {i+1}/{len(X_test)} ìƒ˜í”Œ ì™„ë£Œ")

        logger.info("=" * 70)
        logger.info("âœ… ëª¨ë“  ìƒ˜í”Œ í‰ê°€ ì™„ë£Œ")

    def calculate_metrics(self):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ ê³„ì‚°"""
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ“Š ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ ê³„ì‚° ì¤‘...")
        logger.info("=" * 70)

        total_samples = len(self.sample_results)

        # ì´ìƒ ê°ì§€ í†µê³„
        anomalies_detected = sum(1 for r in self.sample_results if r.is_anomaly)
        adjustments_made = sum(1 for r in self.sample_results if r.adjustment_applied)

        # ì˜ˆì¸¡ ì •í™•ë„ (MAE)
        baseline_predictions = [r.baseline_prediction for r in self.sample_results]
        adjusted_predictions = [r.adjusted_prediction for r in self.sample_results]
        ground_truths = [r.ground_truth for r in self.sample_results]

        baseline_mae = mean_absolute_error(ground_truths, baseline_predictions)
        adjusted_mae = mean_absolute_error(ground_truths, adjusted_predictions)
        mae_improvement_pct = (baseline_mae - adjusted_mae) / baseline_mae * 100

        # ë¶ˆëŸ‰ í†µê³„
        defects_before = sum(1 for r in self.sample_results if not r.meets_threshold_baseline)
        defects_after = sum(1 for r in self.sample_results if not r.meets_threshold_adjusted)
        defects_prevented = sum(1 for r in self.sample_results if r.defect_prevented)

        # ë¶ˆëŸ‰ ê°ì†Œìœ¨
        if defects_before > 0:
            defect_reduction_rate = defects_prevented / defects_before
        else:
            defect_reduction_rate = 0.0

        # í’ˆì§ˆ íšŒë³µìœ¨
        if anomalies_detected > 0:
            quality_recovery_rate = defects_prevented / anomalies_detected
        else:
            quality_recovery_rate = 0.0

        # ë¹„ìš© ì ˆê°
        estimated_cost_saving = defects_prevented * self.cost_per_defect

        # ì¡°ì • íš¨ê³¼ì„±
        adjustments_with_improvement = [
            r for r in self.sample_results
            if r.adjustment_applied and r.improvement > 0
        ]
        successful_adjustments = len(adjustments_with_improvement)

        if adjustments_made > 0:
            adjustment_success_rate = successful_adjustments / adjustments_made
            avg_improvement = np.mean([r.improvement for r in adjustments_with_improvement]) if adjustments_with_improvement else 0.0
        else:
            adjustment_success_rate = 0.0
            avg_improvement = 0.0

        # ì§€í‘œ ì €ì¥
        self.service_metrics = ServiceMetrics(
            total_samples=total_samples,
            anomalies_detected=anomalies_detected,
            adjustments_made=adjustments_made,
            baseline_mae=baseline_mae,
            adjusted_mae=adjusted_mae,
            mae_improvement_pct=mae_improvement_pct,
            defects_before_adjustment=defects_before,
            defects_after_adjustment=defects_after,
            defects_prevented=defects_prevented,
            defect_reduction_rate=defect_reduction_rate,
            quality_recovery_rate=quality_recovery_rate,
            cost_per_defect=self.cost_per_defect,
            estimated_cost_saving=estimated_cost_saving,
            avg_improvement_per_adjustment=avg_improvement,
            successful_adjustments=successful_adjustments,
            adjustment_success_rate=adjustment_success_rate
        )

        # ê²°ê³¼ ì¶œë ¥
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ“Š ì„œë¹„ìŠ¤ í‰ê°€ ê²°ê³¼ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)")
        logger.info("=" * 70)

        logger.info("\n[ê¸°ë³¸ í†µê³„]")
        logger.info(f"  ì´ ìƒ˜í”Œ ìˆ˜: {total_samples}")
        logger.info(f"  ê°ì§€ëœ ì´ìƒ: {anomalies_detected} ({anomalies_detected/total_samples*100:.1f}%)")
        logger.info(f"  ì ìš©ëœ ì¡°ì •: {adjustments_made}")

        logger.info("\n[ì˜ˆì¸¡ ì •í™•ë„]")
        logger.info(f"  ì¡°ì • ì „ MAE: {baseline_mae:.4f}")
        logger.info(f"  ì¡°ì • í›„ MAE: {adjusted_mae:.4f}")
        logger.info(f"  MAE ê°œì„ ìœ¨: {mae_improvement_pct:+.2f}%")

        logger.info("\n[ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸] â­")
        logger.info(f"  ì¡°ì • ì „ ë¶ˆëŸ‰: {defects_before}ê°œ")
        logger.info(f"  ì¡°ì • í›„ ë¶ˆëŸ‰: {defects_after}ê°œ")
        logger.info(f"  ë°©ì§€ëœ ë¶ˆëŸ‰: {defects_prevented}ê°œ")
        logger.info(f"  ë¶ˆëŸ‰ ê°ì†Œìœ¨: {defect_reduction_rate:.1%}")
        logger.info(f"  í’ˆì§ˆ íšŒë³µìœ¨: {quality_recovery_rate:.1%}")
        logger.info(f"  ë¹„ìš© ì ˆê°ì•¡: ${estimated_cost_saving:,.2f}")

        logger.info("\n[ì¡°ì • íš¨ê³¼ì„±]")
        logger.info(f"  ì„±ê³µí•œ ì¡°ì •: {successful_adjustments}/{adjustments_made}")
        logger.info(f"  ì¡°ì • ì„±ê³µë¥ : {adjustment_success_rate:.1%}")
        logger.info(f"  ì¡°ì •ë‹¹ í‰ê·  ê°œì„ : {avg_improvement:.4f}")

        logger.info("=" * 70)

    def _convert_to_python_types(self, obj):
        """numpy íƒ€ì…ì„ Python íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
        if isinstance(obj, dict):
            return {key: self._convert_to_python_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_to_python_types(item) for item in obj]
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return obj

    def save_results(self):
        """í‰ê°€ ê²°ê³¼ ì €ì¥"""
        output_dir = Path("models")
        output_dir.mkdir(parents=True, exist_ok=True)

        # 1. ì„œë¹„ìŠ¤ ì§€í‘œ JSON ì €ì¥
        metrics_path = output_dir / "service_evaluation_results.json"
        metrics_dict = {
            "evaluation_date": datetime.now().isoformat(),
            "metrics": asdict(self.service_metrics)
        }

        # numpy íƒ€ì…ì„ Python íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        metrics_dict = self._convert_to_python_types(metrics_dict)

        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics_dict, f, indent=2, ensure_ascii=False)
        logger.info(f"\nâœ… ì„œë¹„ìŠ¤ ì§€í‘œ ì €ì¥: {metrics_path}")

        # 2. ìƒ˜í”Œë³„ ê²°ê³¼ CSV ì €ì¥
        samples_path = output_dir / "service_evaluation_samples.csv"
        samples_df = pd.DataFrame([asdict(r) for r in self.sample_results])
        samples_df.to_csv(samples_path, index=False)
        logger.info(f"âœ… ìƒ˜í”Œë³„ ê²°ê³¼ ì €ì¥: {samples_path}")

        # 3. í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ì €ì¥
        report_path = output_dir / "service_evaluation_report.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 70 + "\n")
            f.write("SmartFlow ì„œë¹„ìŠ¤ í‰ê°€ ë¦¬í¬íŠ¸ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)\n")
            f.write("=" * 70 + "\n\n")
            f.write(f"í‰ê°€ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Test ìƒ˜í”Œ ìˆ˜: {self.service_metrics.total_samples}\n\n")

            f.write("=" * 70 + "\n")
            f.write("ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ (í•µì‹¬ ì§€í‘œ)\n")
            f.write("=" * 70 + "\n")
            f.write(f"ê°ì§€ëœ ì´ìƒ: {self.service_metrics.anomalies_detected}ê±´\n")
            f.write(f"ë°©ì§€ëœ ë¶ˆëŸ‰: {self.service_metrics.defects_prevented}ê±´\n")
            f.write(f"ë¶ˆëŸ‰ ê°ì†Œìœ¨: {self.service_metrics.defect_reduction_rate:.1%}\n")
            f.write(f"í’ˆì§ˆ íšŒë³µìœ¨: {self.service_metrics.quality_recovery_rate:.1%}\n")
            f.write(f"ë¹„ìš© ì ˆê°ì•¡: ${self.service_metrics.estimated_cost_saving:,.2f}\n\n")

            f.write("=" * 70 + "\n")
            f.write("ì˜ˆì¸¡ ì •í™•ë„ (Ground Truth ê¸°ë°˜)\n")
            f.write("=" * 70 + "\n")
            f.write(f"ì¡°ì • ì „ MAE: {self.service_metrics.baseline_mae:.4f}\n")
            f.write(f"ì¡°ì • í›„ MAE: {self.service_metrics.adjusted_mae:.4f}\n")
            f.write(f"MAE ê°œì„ ìœ¨: {self.service_metrics.mae_improvement_pct:+.2f}%\n\n")

            f.write("=" * 70 + "\n")
            f.write("ì¡°ì • ì‹œìŠ¤í…œ íš¨ê³¼ì„±\n")
            f.write("=" * 70 + "\n")
            f.write(f"ì ìš©ëœ ì¡°ì •: {self.service_metrics.adjustments_made}íšŒ\n")
            f.write(f"ì„±ê³µí•œ ì¡°ì •: {self.service_metrics.successful_adjustments}íšŒ\n")
            f.write(f"ì¡°ì • ì„±ê³µë¥ : {self.service_metrics.adjustment_success_rate:.1%}\n")
            f.write(f"ì¡°ì •ë‹¹ í‰ê·  ê°œì„ : {self.service_metrics.avg_improvement_per_adjustment:.4f}\n\n")

            f.write("=" * 70 + "\n")
            f.write("âš ï¸ ì´ ê²°ê³¼ëŠ” Test ë°ì´í„° ê¸°ë°˜ ì‹¤ì œ ì„±ëŠ¥ì…ë‹ˆë‹¤.\n")
            f.write("=" * 70 + "\n")

        logger.info(f"âœ… í‰ê°€ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "=" * 70)
    print("ğŸ”¬ SmartFlow ì„œë¹„ìŠ¤ ì „ì²´ í‰ê°€ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)")
    print("=" * 70)
    print("âš ï¸  Test ë°ì´í„°ë¡œ Multi-Agent ì‹œìŠ¤í…œì˜ ì‹¤ì œ ì„±ëŠ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤.")
    print("ì´ í‰ê°€ëŠ” íŒŒë¼ë¯¸í„° ì¡°ì • ì‹œìŠ¤í…œì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.")
    print("=" * 70)

    try:
        evaluator = ServiceEvaluator(
            quality_threshold=0.90,
            cost_per_defect=100.0
        )

        # 1. ì¤€ë¹„
        evaluator.load_artifacts()

        # 2. í‰ê°€
        evaluator.evaluate_samples()

        # 3. ì§€í‘œ ê³„ì‚°
        evaluator.calculate_metrics()

        # 4. ê²°ê³¼ ì €ì¥
        evaluator.save_results()

        print("\n" + "=" * 70)
        print("âœ… ì„œë¹„ìŠ¤ í‰ê°€ ì™„ë£Œ!")
        print("=" * 70)
        print("ê²°ê³¼ íŒŒì¼:")
        print("  - models/service_evaluation_results.json (JSON ì§€í‘œ)")
        print("  - models/service_evaluation_samples.csv (ìƒ˜í”Œë³„ ê²°ê³¼)")
        print("  - models/service_evaluation_report.txt (í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸)")
        print("=" * 70)

    except FileNotFoundError as e:
        logger.error(f"âŒ {e}")
        sys.exit(1)
    except Exception as e:
        logger.exception(f"âŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
