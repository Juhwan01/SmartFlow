"""
ML ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (ìµœì¢… ìˆ˜ì •ë²„ì „ - XGBoost 2.0+ í˜¸í™˜)

1. XGBoost 2.0+ í˜¸í™˜ì„± ì™„ë²½ ìˆ˜ì • (eval_metric, early_stopping_rounds ìœ„ì¹˜ ë³€ê²½)
2. ë¹„ì¦ˆë‹ˆìŠ¤ KPI (MAE, MAPE) ì¤‘ì‹¬ì˜ í•™ìŠµ ë° í‰ê°€
3. ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ Feature Engineering ì ìš©
"""
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import numpy as np
import pandas as pd
import pickle
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import xgboost as xgb
from loguru import logger
import json

from src.data.data_preprocessing import ManufacturingDataProcessor


class ModelTrainer:
    """ëª¨ë¸ í•™ìŠµê¸°"""

    def __init__(self):
        self.processor = ManufacturingDataProcessor()
        self.model = None
        self.metrics = {}
        self.scaler = MinMaxScaler() # ìì²´ ìŠ¤ì¼€ì¼ëŸ¬ ì‚¬ìš©

    def _calculate_mape(self, y_true, y_pred):
        """MAPE ê³„ì‚° (ì •ë°€ë„ ì§€í‘œ)"""
        threshold = 0.1
        mask = np.abs(y_true) > threshold
        if mask.sum() == 0:
            return 0.0
        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

    def feature_engineering(self, df):
        """ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ë³€ìˆ˜ ì¶”ê°€"""
        df_fe = df.copy()
        
        # 1. ìš©ì ‘ ì…ì—´ëŸ‰ (Heat Input) ìœ ì‚¬ ë³€ìˆ˜
        df_fe['heat_input_proxy'] = df_fe['welding_temp1'] / (df_fe['welding_temp3'] + 1e-5)

        # 2. ì••ë ¥ê³¼ ì˜¨ë„ì˜ ìƒí˜¸ì‘ìš©
        df_fe['pressure_x_temp2'] = df_fe['welding_pressure'] * df_fe['welding_temp2']
        
        # 3. ì œì–´ ë³€ìˆ˜ í•©ê³„
        df_fe['total_control'] = df_fe['welding_control1'] + df_fe['welding_control2']

        # 4. í”„ë ˆìŠ¤ ê³µì •ì˜ ë©´ì /ë¶€í”¼ ìœ ì‚¬ ë³€ìˆ˜
        df_fe['press_volume_proxy'] = df_fe['press_thickness'] * df_fe['press_measurement1']

        # 5. ì „ì²´ ì„¸íŠ¸í¬ì¸íŠ¸ ëŒ€ë¹„ í¸ì°¨/ë¹„ìœ¨ íŠ¹ì„± ìƒì„± (íƒ€ê¹ƒ ì—´ ì œì™¸)
        target_col = 'welding_strength'
        setpoint_cols = [col for col in df_fe.columns if col.endswith('_setpoint')]
        for setpoint_col in setpoint_cols:
            actual_col = setpoint_col.replace('_setpoint', '')
            if actual_col == target_col:
                continue  # íƒ€ê¹ƒ ìœ ì¶œ ë°©ì§€
            if actual_col in df_fe.columns:
                error_col = f"{actual_col}_error"
                ratio_col = f"{actual_col}_ratio"
                df_fe[error_col] = df_fe[actual_col] - df_fe[setpoint_col]
                df_fe[ratio_col] = np.where(
                    df_fe[setpoint_col] != 0,
                    df_fe[actual_col] / df_fe[setpoint_col],
                    1.0
                )

        # Stage1 ì¸¡ì •ì¹˜ ì§‘ê³„ í†µê³„
        stage_error_cols = [
            col for col in df_fe.columns
            if col.startswith('stage1_measurement') and col.endswith('_error')
        ]
        if stage_error_cols:
            stage_error_df = df_fe[stage_error_cols]
            df_fe['stage1_error_mean'] = stage_error_df.mean(axis=1)
            df_fe['stage1_error_std'] = stage_error_df.std(axis=1).fillna(0)
            df_fe['stage1_error_abs_max'] = stage_error_df.abs().max(axis=1)

        stage_ratio_cols = [
            col for col in df_fe.columns
            if col.startswith('stage1_measurement') and col.endswith('_ratio')
        ]
        if stage_ratio_cols:
            stage_ratio_df = df_fe[stage_ratio_cols]
            df_fe['stage1_ratio_mean'] = stage_ratio_df.mean(axis=1)
            df_fe['stage1_ratio_std'] = stage_ratio_df.std(axis=1).fillna(0)

        # Machineë³„ Derived Features
        def add_diff(col_a, col_b, new_col):
            if col_a in df_fe.columns and col_b in df_fe.columns:
                df_fe[new_col] = df_fe[col_a] - df_fe[col_b]

        add_diff('machine1_zone1_temp', 'machine1_zone2_temp', 'machine1_zone_temp_diff')
        add_diff('machine2_zone1_temp', 'machine2_zone2_temp', 'machine2_zone_temp_diff')
        add_diff('machine3_zone1_temp', 'machine3_zone2_temp', 'machine3_zone_temp_diff')
        add_diff('welding_temp5', 'welding_temp1', 'welding_temp_span')
        add_diff('combiner_temp3', 'combiner_temp1', 'combiner_temp_gradient')

        def add_power_proxy(amperage_col, rpm_col, new_col):
            if amperage_col in df_fe.columns and rpm_col in df_fe.columns:
                df_fe[new_col] = df_fe[amperage_col] * df_fe[rpm_col]

        add_power_proxy('machine1_motor_amperage', 'machine1_motor_rpm', 'machine1_power_proxy')
        add_power_proxy('machine2_motor_amperage', 'machine2_motor_rpm', 'machine2_power_proxy')
        add_power_proxy('machine3_motor_amperage', 'machine3_motor_rpm', 'machine3_power_proxy')

        # Raw material ì¡°ì„± í‰ê· 
        for prop_idx in range(1, 5):
            cols = [
                f"machine{machine_idx}_raw_property{prop_idx}"
                for machine_idx in (1, 2, 3)
                if f"machine{machine_idx}_raw_property{prop_idx}" in df_fe.columns
            ]
            if len(cols) >= 2:
                df_fe[f"raw_property{prop_idx}_avg"] = df_fe[cols].mean(axis=1)

        # Ambient & Welding í™˜ê²½ ì§€ìˆ˜
        if {'ambient_temperature', 'ambient_humidity'} <= set(df_fe.columns):
            df_fe['ambient_index'] = (
                df_fe['ambient_temperature'] * 0.7 + df_fe['ambient_humidity'] * 0.3
            )

        temp_features = [col for col in ['welding_temp1', 'welding_temp2', 'welding_temp3', 'welding_temp4', 'welding_temp5'] if col in df_fe.columns]
        if temp_features:
            df_fe['welding_temp_mean'] = df_fe[temp_features].mean(axis=1)

        machine5_temps = [col for col in ['machine5_temp3', 'machine5_temp4', 'machine5_temp5', 'machine5_temp6'] if col in df_fe.columns]
        if machine5_temps:
            df_fe['machine5_temp_mean'] = df_fe[machine5_temps].mean(axis=1)

        # Temporal Features (1-step lag, rolling mean, trend)
        temporal_cols = [
            'press_thickness',
            'stage1_error_mean',
            'welding_temp1',
            'welding_temp3',
            'welding_pressure',
            'ambient_temperature'
        ]

        for col in temporal_cols:
            if col in df_fe.columns:
                lag_col = f"{col}_lag1"
                roll_col = f"{col}_roll3"
                trend_col = f"{col}_trend"
                df_fe[lag_col] = df_fe[col].shift(1)
                df_fe[roll_col] = df_fe[col].rolling(window=3, min_periods=1).mean()
                df_fe[lag_col] = df_fe[lag_col].fillna(df_fe[col])
                df_fe[roll_col] = df_fe[roll_col].fillna(df_fe[col])
                df_fe[trend_col] = df_fe[col] - df_fe[lag_col]

        # ì„¸íŠ¸í¬ì¸íŠ¸ ì»¬ëŸ¼ ë“œë¡­ (ëˆ„ì„¤ ë°©ì§€)
        drop_cols = [col for col in df_fe.columns if col.endswith('_setpoint')]
        df_fe = df_fe.drop(columns=drop_cols, errors='ignore')

        # ë‚¨ì€ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df_fe = df_fe.ffill().bfill()

        return df_fe

    def train_xgboost(
        self,
        n_estimators: int = 2000,
        max_depth: int = 8,
        learning_rate: float = 0.02
    ):
        logger.info("=" * 70)
        logger.info("XGBoost ëª¨ë¸ í•™ìŠµ ì‹œì‘ (KPI: MAE ìµœì†Œí™”)")
        logger.info("=" * 70)

        # 1. ë°ì´í„° ë¡œë“œ
        df = self.processor.create_mapped_dataset()
        target_col = "welding_strength"

        # 2. 0ê°’ ë°ì´í„° í•„í„°ë§
        initial_len = len(df)
        df = df[df[target_col] > 0.1].copy()
        logger.info(f"ë°ì´í„° í•„í„°ë§: {initial_len} -> {len(df)} (ìœ íš¨ ê³µì • ë°ì´í„°ë§Œ ì‚¬ìš©)")

        # 3. Feature Engineering ì ìš©
        df_fe = self.feature_engineering(df)
        feature_cols = [col for col in df_fe.columns if col != target_col]

        X = df_fe[feature_cols].values
        y = df_fe[target_col].values

        # 4. ìŠ¤ì¼€ì¼ë§
        X_scaled = self.scaler.fit_transform(X)

        # 5. Train/Validation/Test ë¶„ë¦¬ (70/15/15)
        # Step 1: Train+Val / Test ë¶„ë¦¬
        X_trainval, X_test, y_trainval, y_test = train_test_split(
            X_scaled, y, test_size=0.15, random_state=42
        )

        # Step 2: Train / Validation ë¶„ë¦¬
        X_train, X_val, y_train, y_val = train_test_split(
            X_trainval, y_trainval, test_size=0.176, random_state=42  # 0.176 â‰ˆ 15/(70+15)
        )

        logger.info(f"ë°ì´í„° ë¶„í• : Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}")

        # 6. Train/Val/Test ë°ì´í„° ì €ì¥
        data_dir = Path("data")
        data_dir.mkdir(parents=True, exist_ok=True)

        # Train ë°ì´í„° ì €ì¥ (RAGìš©)
        train_df = pd.DataFrame(X_train, columns=feature_cols)
        train_df[target_col] = y_train
        train_path = data_dir / "train_set.csv"
        train_df.to_csv(train_path, index=False)
        logger.info(f"âœ… Train ë°ì´í„° ì €ì¥: {train_path} ({len(train_df)} samples, RAGìš©)")

        # Validation ë°ì´í„° ì €ì¥
        val_df = pd.DataFrame(X_val, columns=feature_cols)
        val_df[target_col] = y_val
        val_path = data_dir / "val_set.csv"
        val_df.to_csv(val_path, index=False)
        logger.info(f"âœ… Validation ë°ì´í„° ì €ì¥: {val_path} ({len(val_df)} samples)")

        # Test ë°ì´í„° ì €ì¥ (ìµœì¢… í‰ê°€ìš©)
        test_df = pd.DataFrame(X_test, columns=feature_cols)
        test_df[target_col] = y_test
        test_path = data_dir / "test_set.csv"
        test_df.to_csv(test_path, index=False)
        logger.info(f"âœ… Test ë°ì´í„° ì €ì¥: {test_path} ({len(test_df)} samples, ìµœì¢… í‰ê°€ìš©, ì ˆëŒ€ ì¬í•™ìŠµ ê¸ˆì§€)")

        # 6-1. Sample Weighting ê³„ì‚° (ë¶ˆëŸ‰í’ˆ ê°•ì¡° í•™ìŠµ)
        # ===================================================================
        # ë¶ˆê· í˜• ë°ì´í„° ëŒ€ì‘: ë¶ˆëŸ‰ ìƒ˜í”Œì— ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
        # ì°¸ê³ : 2024 ì œì¡° ë¶ˆëŸ‰ ê°ì§€ ì—°êµ¬ (MDPI Sensors)
        # ===================================================================
        # Config ê¸°ë°˜ í’ˆì§ˆ ê¸°ì¤€ ì‚¬ìš© (ì—…ê³„ í‘œì¤€)
        from config import settings
        LSL = settings.welding_strength_lsl  # 11.50
        USL = settings.welding_strength_usl  # 13.20

        # Train ë°ì´í„°ì—ì„œ ë¶ˆëŸ‰ ìƒ˜í”Œ ì‹ë³„
        train_defects = (y_train < LSL) | (y_train > USL)
        num_defects = train_defects.sum()
        num_normal = len(y_train) - num_defects

        # ê°€ì¤‘ì¹˜ ê³„ì‚°: ë¶ˆëŸ‰ ìƒ˜í”Œì— ì •ìƒ/ë¶ˆëŸ‰ ë¹„ìœ¨ë§Œí¼ ê°€ì¤‘ì¹˜ ë¶€ì—¬
        if num_defects > 0:
            raw_weight = num_normal / num_defects
            defect_weight = min(raw_weight, 50.0)
            if defect_weight < raw_weight:
                logger.info(
                    f"  - ë¶ˆëŸ‰ ê°€ì¤‘ì¹˜ ìº¡ ì ìš©: ì›ë˜ {raw_weight:.1f} -> ì‚¬ìš© {defect_weight:.1f}"
                )
        else:
            defect_weight = 1.0

        # Sample weights ìƒì„±
        sample_weights = np.ones(len(y_train))
        sample_weights[train_defects] = defect_weight

        logger.info(f"\në¶ˆê· í˜• ë°ì´í„° ëŒ€ì‘:")
        logger.info(f"  - ì •ìƒ ìƒ˜í”Œ: {num_normal}ê°œ (ê°€ì¤‘ì¹˜: 1.0)")
        logger.info(f"  - ë¶ˆëŸ‰ ìƒ˜í”Œ: {num_defects}ê°œ (ê°€ì¤‘ì¹˜: {defect_weight:.1f})")
        logger.info(f"  - ë¶ˆëŸ‰ë¥ : {num_defects/len(y_train)*100:.2f}%")

        # 7. ëª¨ë¸ í•™ìŠµ (Validation ë°ì´í„°ë¡œ Early Stopping)
        self.model = xgb.XGBRegressor(
            n_estimators=n_estimators,
            max_depth=max_depth,
            learning_rate=learning_rate,
            min_child_weight=1,
            max_delta_step=1,  # ê·¹ë‹¨ê°’ í•™ìŠµ ê°œì„ 
            subsample=0.8,
            colsample_bytree=0.8,
            early_stopping_rounds=50,
            eval_metric='mae',
            objective='reg:squarederror',
            random_state=42,
            n_jobs=-1
        )

        logger.info("\nëª¨ë¸ í•™ìŠµ ì¤‘ (ë¶ˆëŸ‰ ìƒ˜í”Œ ê°•ì¡° í•™ìŠµ + Validation Early Stopping)...")

        # Validation ë°ì´í„°ë¡œ early stopping (sample_weight ì ìš©)
        self.model.fit(
            X_train, y_train,
            sample_weight=sample_weights,  # ë¶ˆëŸ‰ ìƒ˜í”Œ ê°•ì¡°!
            eval_set=[(X_val, y_val)],
            verbose=False
        )

        # 8. ì˜ˆì¸¡ ë° í‰ê°€ (Train, Validationë§Œ - TestëŠ” evaluate_final.pyì—ì„œ)
        y_pred_train = self.model.predict(X_train)
        y_pred_val = self.model.predict(X_val)

        self.metrics = {
            "train": {
                "mae": mean_absolute_error(y_train, y_pred_train),
                "rmse": np.sqrt(mean_squared_error(y_train, y_pred_train)),
                "mape": self._calculate_mape(y_train, y_pred_train)
            },
            "validation": {
                "mae": mean_absolute_error(y_val, y_pred_val),
                "rmse": np.sqrt(mean_squared_error(y_val, y_pred_val)),
                "mape": self._calculate_mape(y_val, y_pred_val)
            },
            "test": {
                "note": "Test í‰ê°€ëŠ” scripts/evaluate_final.pyì—ì„œ ë‹¨ 1íšŒë§Œ ìˆ˜í–‰",
                "test_set_path": "data/test_set.csv"
            }
        }

        # ê²°ê³¼ ì¶œë ¥
        logger.info("\n" + "=" * 70)
        logger.info("í•™ìŠµ ê²°ê³¼ (Validation Set)")
        logger.info("=" * 70)
        logger.info(f"âœ… MAE (í‰ê·  ì˜¤ì°¨): {self.metrics['validation']['mae']:.4f} (ëª©í‘œ: < 0.2)")
        logger.info(f"âœ… MAPE (ì˜¤ì°¨ìœ¨)  : {self.metrics['validation']['mape']:.2f}%  (ëª©í‘œ: < 2%)")
        logger.info("=" * 70)
        logger.info("âš ï¸  Test ë°ì´í„° í‰ê°€ëŠ” scripts/evaluate_final.pyì—ì„œ ë‹¨ 1íšŒë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        logger.info("=" * 70)

        # Feature Importance
        logger.info("\n[í•µì‹¬ ì˜í–¥ ë³€ìˆ˜ - Top 5]")
        feature_importance = self.model.feature_importances_
        importance_dict = dict(zip(feature_cols, feature_importance))
        sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)
        for i, (feature, importance) in enumerate(sorted_importance[:5], 1):
            logger.info(f"  {i}. {feature}: {importance:.4f}")

        return self.model, self.metrics

    def save_model(self, model_path: str = "models/quality_predictor.pkl"):
        """ëª¨ë¸ ë° ê´€ë ¨ íŒŒì¼ ì €ì¥"""
        if self.model is None:
            return

        Path(model_path).parent.mkdir(parents=True, exist_ok=True)
        
        with open(model_path, 'wb') as f:
            pickle.dump(self.model, f)
        
        with open("models/scaler.pkl", 'wb') as f:
            pickle.dump(self.scaler, f)

        with open("models/metrics.json", 'w') as f:
            json.dump(self.metrics, f, indent=2)
            
        with open("models/variable_mapping.json", 'w', encoding='utf-8') as f:
            json.dump(self.processor.variable_mapping, f, indent=2, ensure_ascii=False)
            
        logger.info(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

def main():
    logger.info("SmartFlow ML Model Training (Business KPI Optimized)")

    trainer = ModelTrainer()
    model, metrics = trainer.train_xgboost()
    trainer.save_model()

    print("\n" + "=" * 70)
    print("ğŸ¯ í•™ìŠµ ì„±ëŠ¥ ìš”ì•½ (Validation Set)")
    print("=" * 70)

    mae_score = metrics['validation']['mae']
    mape_score = metrics['validation']['mape']

    print(f"âœ… Validation MAE  : {mae_score:.4f} (ëª©í‘œ: < 0.2)")
    print(f"âœ… Validation MAPE : {mape_score:.2f}% (ëª©í‘œ: < 2.0%)")

    if mae_score < 0.2:
        print("\nğŸ‰ ëª©í‘œ ë‹¬ì„±! í˜„ì¥ íˆ¬ì… ê°€ëŠ¥í•œ ì´ˆì •ë°€ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
        print("   (í‰ê·  ì˜¤ì°¨ 0.2 ë¯¸ë§Œìœ¼ë¡œ í’ˆì§ˆ ì œì–´ ê°€ëŠ¥)")
    else:
        print(f"\nâš ï¸  ì¶”ê°€ íŠœë‹ í•„ìš” (í˜„ì¬ ì˜¤ì°¨: {mae_score:.4f})")

    print("=" * 70)
    print("âš ï¸  ìµœì¢… Test í‰ê°€ëŠ” 'python scripts/evaluate_final.py'ë¡œ ìˆ˜í–‰í•˜ì„¸ìš”.")
    print("=" * 70)

if __name__ == "__main__":
    main()